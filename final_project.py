# -*- coding: utf-8 -*-
"""Final Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Rr2osBVPBOWxmJd59LwIl52PAFgoDM2Q
"""

# Commented out IPython magic to ensure Python compatibility.
#essential libraries
import numpy as np
from scipy import signal
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from matplotlib import cm
from skimage import draw as drw
from skimage import data, color, exposure, img_as_float, img_as_ubyte, morphology, filters
from skimage import io
from scipy import ndimage
from scipy.ndimage import label, center_of_mass
import os
import cv2
import math
from skimage.filters import threshold_otsu

import skimage
# %matplotlib inline

from google.colab import drive
drive.mount('/content/drive')

"""## 1- Background
Let's visualize an empty scene captured by a fixed camera, and the same scene where objects are present
"""

filename='drive/MyDrive/COMPUTATIONAL VISION/2024/Lab3_sketch/images/es1/EmptyScene01.jpg'
I1=io.imread(filename)
filename='drive/MyDrive/COMPUTATIONAL VISION/2024/Lab3_sketch/images/es1/EmptyScene02.jpg'
I2=io.imread(filename)
Ig1=img_as_float(color.rgb2gray(I1))
Ig2=img_as_float(color.rgb2gray(I2))

plt.subplot(121)
plt.imshow(Ig1,cmap='gray')
plt.title('Immagine 1')
plt.subplot(122)
plt.imshow(Ig2,cmap='gray')
plt.title('Immagine 2');

"""Let's try to see the difference in terms of Grayscale intensities of corresponding pixels across the two images"""

D = Ig1 - Ig2

plt.imshow(D,cmap='gray')
plt.title('Difference')
plt.colorbar()
plt.show()

"""Indeed, the difference seems to be small for most pixels:"""

# multiplying by 255 to get a feeling of the differences entity
# with respect to input values
plt.hist(255*D.ravel(),100);

"""# Analysis
Comment the histogram you just visualized:

The histogram is not completely symmetric but it's almost symmetric. So, it is
quasi gaussian and the peak is in zero.and there are a little differences between brightness of the two images.

#2- Change detection
 italicized textYou may try out different frames
"""

threshold = 0.3 #let's pick a threshold
listofDabs= []
path='drive/MyDrive/COMPUTATIONAL VISION/2024/project/images/es1/video'
#files= os.listdir(path)
files = sorted(os.listdir(path))
for file in files:
  It=io.imread(os.path.join(path, file))
  Itg=img_as_float(color.rgb2gray(It))
  # check slide "Motion segmentation - CHANGE DETECTION"


  #threshold = threshold_otsu(Itg)
  #Dabs = (abs(Ig1 - Itg) > threshold)


  Dabs=( abs(Ig1 - Itg)> threshold)
  listofDabs.append(Dabs)
  plt.imshow(Dabs,cmap='gray')
  plt.show()

# Kernel for morphological operations
kernel = np.ones((3, 3), np.uint8)

#list to store the dilated images
dilated_images = []

# Perform dilation on each Dabs image
for i, Dabs in enumerate(listofDabs):
    dilated_image = cv2.dilate(Dabs.astype(np.uint8), kernel, iterations=6)
    dilated_images.append(dilated_image)

# Perform erosion on each dilated image
eroded_images = []  # List to store the eroded images
for dilated_image in dilated_images:
    eroded_image = cv2.erode(dilated_image, kernel, iterations=4)
    eroded_images.append(eroded_image)

min_size = 100

for image_idx, eroded_image in enumerate(eroded_images):
    label_objects, num_labels = ndimage.label(eroded_image)

    # Filtering small regions based on the component size
    binary_cleaned = np.zeros_like(label_objects, dtype=np.uint8) #initialized zeros(black background) for  each connected component.

    for comp_idx in range(1, num_labels + 1):
        component_size = np.sum(label_objects == comp_idx)

        if component_size >= min_size:
            binary_cleaned[label_objects == comp_idx] = 255 # if the compoent size is greater than the threshold(min-size) it become white.

    # re-Label the cleaned binary image
    label_objects, num_filtered_labels = ndimage.label(binary_cleaned > 0)

    # Display the results
    plt.imshow(label_objects, cmap='nipy_spectral')
    plt.title(f"Labeled Components in Image {image_idx + 1} (n={num_filtered_labels})")
    plt.colorbar()
    plt.show()

entroids_list = []  # List to store centroids for each frame
object_ids = []  # List to store object IDs for each frame
active_objects = {}  # Dictionary to track active objects with their last known centroid
object_trajectories = {}  #  is a dictionary used to keep track of active objects and their last known centroids.


min_size = 100  # Minimum size for an object to be considered
max_distance = 50  # Maximum allowed distance to match centroids( If the distance between the centroids of objects in consecutive frames is smaller than this value, the objects are considered the same.)

for frame_idx, eroded_image in enumerate(eroded_images):
    label_objects, num_labels = ndimage.label(eroded_image)  # Label the components in the current frame


    current_centroids = []
    centroids_with_ids = []

    for i in range(1, num_labels + 1):
        component_size = np.sum(label_objects == i)
        if component_size >= min_size:
            centroid = center_of_mass(eroded_image, label_objects, i)
            current_centroids.append(centroid)

    if frame_idx > 0:
        matched_ids = set()
        for current_centroid in current_centroids:
            min_distance = float('inf')
            best_match_id = None

            # find the nearest active object
            for obj_id, last_centroid in active_objects.items():
                if obj_id in matched_ids:
                    continue  # Skip already matched objects
                distance = np.linalg.norm(np.array(current_centroid) - np.array(last_centroid))
                if distance < min_distance:
                    min_distance = distance
                    best_match_id = obj_id

            if min_distance <= max_distance and best_match_id is not None:
                # Match found, update the active object
                matched_ids.add(best_match_id)
                active_objects[best_match_id] = current_centroid
                centroids_with_ids.append({'id': best_match_id, 'centroid': current_centroid})
                # Add current centroid to trajectory
                object_trajectories[best_match_id].append(current_centroid)
            else:
                # if no match found, assign a new ID
                new_id = len(active_objects)
                active_objects[new_id] = current_centroid
                centroids_with_ids.append({'id': new_id, 'centroid': current_centroid})
                object_trajectories[new_id] = [current_centroid]  # Initialize trajectory for the new object
    else:
        # For the first frame, assign unique IDs
        for i, centroid in enumerate(current_centroids):
            active_objects[i] = centroid
            centroids_with_ids.append({'id': i, 'centroid': centroid})
            object_trajectories[i] = [centroid]  # Initialize trajectory for the new object
    print('object_trajectories',len(object_trajectories))
    # Update object_ids and plot the results
    object_ids.append(centroids_with_ids)

    plt.figure(figsize=(8, 8))
    plt.imshow(label_objects, cmap='gray')
    for centroid_data in centroids_with_ids:
        centroid = centroid_data['centroid']
        plt.scatter(centroid[1], centroid[0], color='red', marker='x')
        plt.text(centroid[1] + 5, centroid[0] + 5, f'ID:{centroid_data["id"]}', color='red')
    plt.title(f"Centroids and IDs in Frame {frame_idx + 1}")
    plt.show()

print('items', len(object_trajectories))

# Print object trajectories
print("Trajectories of All Objects:")
for obj_id, trajectory in object_trajectories.items():
    print(f"Object {obj_id + 1} Trajectory: {trajectory}")
#plotting
plt.figure(figsize=(10, 6))
for obj_id, trajectory in object_trajectories.items():
    # Plot the trajectory for each object
    plt.plot(
        [p[1] for p in trajectory],  # X-coordinates
        [p[0] for p in trajectory],  # Y-coordinates
        label=f'Object {obj_id + 1}'
    )
    plt.scatter(
        [p[1] for p in trajectory],  # X-coordinates
        [p[0] for p in trajectory],  # Y-coordinates
        label=f'Centroids of Object {obj_id + 1}',
        s=10
    )

plt.legend()
plt.title("Trajectories of Objects Across Frames")
plt.xlabel("X Position")
plt.ylabel("Y Position")
plt.grid(True)
plt.gca().invert_yaxis()  # Invert Y-axis to match image coordinates
plt.show()

# Compute velocity
velocities = {}
for obj_id, trajectory in object_trajectories.items():
    velocities[obj_id] = []
    for i in range(1, len(trajectory)):
        prev_point = trajectory[i - 1]
        curr_point = trajectory[i]
        velocity = np.linalg.norm(np.array(curr_point) - np.array(prev_point))
        velocities[obj_id].append(velocity)
    print(f"Velocity of Object {obj_id + 1}: {velocities[obj_id]}")

#computing direction
directions = {}
for obj_id, trajectory in object_trajectories.items():
    directions[obj_id] = []
    for i in range(1, len(trajectory)):
        prev_point = trajectory[i - 1]
        curr_point = trajectory[i]
        delta_x = curr_point[1] - prev_point[1]
        delta_y = curr_point[0] - prev_point[0]
        direction = np.degrees(np.arctan2(delta_y, delta_x))

        directions[obj_id].append(direction)
    print(f"Direction of Object {obj_id + 1}: {directions[obj_id]}")

#computing path curcatures
curvatures = {}
for obj_id, trajectory in object_trajectories.items():
    curvatures[obj_id] = []
    for i in range(2, len(trajectory)):
        prev_direction = directions[obj_id][i - 2]
        curr_direction = directions[obj_id][i - 1]
        curvature = abs(curr_direction - prev_direction)
        curvatures[obj_id].append(curvature)
    print(f"Curvature of Object {obj_id + 1}: {curvatures[obj_id]}")